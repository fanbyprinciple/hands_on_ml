{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explore the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make('Pong-v0')\n",
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_animation(frames, repeat=False, interval=40):\n",
    "    plt.close()\n",
    "    fig = plt.figure()\n",
    "    for f in frames:\n",
    "        plt.imshow(f)\n",
    "        plt.axis('off')\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We see the observation space is a 210x160 RGB image. \n",
    "The action space is a Discrete(6) space with 6 different actions: actions 0 and 1 do nothing, actions 2 and 4 move the paddle up, and finally actions 3 and 5 move the paddle down. \n",
    "The paddle is free to move immediately but the ball does not appear until after 18 steps into the episode.\n",
    "\"\"\"\n",
    "\n",
    "# the first argument is a function that takes the curent iteration and produces\n",
    "# an action for the agent to takethe currentiteration and produce an action\n",
    "# for the agent to take\n",
    "\n",
    "def run_episode(policy, n_max_steps=1000, frames_per_action=1):\n",
    "    obs = env.reset()\n",
    "    frames = []\n",
    "    for i in range(n_max_steps):\n",
    "        obs, reward, done, info = env.step(policy(obs,i))\n",
    "        frames.append(env.render(mode='rgb_array'))\n",
    "        if done:\n",
    "            break\n",
    "    return frames\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALQAAADnCAYAAAC313xrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAADcElEQVR4nO3dz00UYRyA4R1DA7o12IEXuJNobIEeTCzEaA+0YDxwh4sdWMPawnogHiS7g8DMzvLyPDfy7Z85vPnyA76dHbbb7QoqXi19ATAlQZMiaFIETYqgSTkZWxyGYfRPIF/fv572auA/fPrxe9i3Nhr0HMGen50+6PFX1zdPev6u1+DWz88fH/ycd1++z3Al0zFykCJoUgRNyugMPYf75tmnztiPeQ1u7ZqPHzNnL8kOTYqgSRE0KQefoc23zMkOTYqgSRE0KQefoe9yzoIp2aFJETQpgiZF0KQs/kvhff9omfowE/s9t4NIu9ihSRE0KYImZRi7t923D2/c+I6jM/apbzs0KYImZXTk2Gw2Rg6Oznq9NnLwMgiaFEGTImhSBE2KoEkRNCmCJkXQpDicxKzufmhgim8AcDiJF0PQpAiaFEGTImhSBE3K4vfloO3QX9RphyZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNysncb3B+dvrPz1fXN3O/JXtcXP5arVar1eXF24WvZD52aFIETYqgSZl9huZ4lGfnv+zQpAiaFEGTImhSBE2KoEkRNCmCJkXQpAiaFEGTMvtZDuefOSQ7NCmCJkXQpAiaFEGTImhSBE2KoEkRNCmCJkXQpAiaFEGTImhSBE2KoEkRNCmCJkXQpAiaFEGTImhSBE2KoEkRNCmCJkXQpAiaFEGTImhSBE3KsN1u9y5uNpv9i7CQ9Xo97FuzQ5MiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJqU0QP+8NzYoUkRNCmCJkXQpAiaFEGT8gdAR1DZL7dYuwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "frames = run_episode(lambda obs, i: np.random.randint(0,5))\n",
    "\n",
    "plot_animation(frames)\n",
    "# try:\n",
    "#     run_episode(lambda obs, i: np.random.randint(0,5))\n",
    "# except Exception as e:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    " let's write a preprocessing function to scale down the input state.\n",
    " Since a single observation does not tell us about the ball's velocity, \n",
    " we will also need to combine multiple observations into a single state. \n",
    " Below is the preprocessing code for this environment. \n",
    " The preprocessing algorithm is two-fold:\n",
    "\n",
    "    Convert the image in the observation to an image to only black and white\n",
    "    and scale it down to 80x80 pixels.\n",
    "\n",
    "    Combine 3 observations into a single state which depicts the \n",
    "    velocity of the paddles and the ball.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "green_paddle_color = (92, 186, 92)\n",
    "red_paddle_color = (213, 130, 74)\n",
    "background_color = (144, 72, 17)\n",
    "ball_color = (236, 236, 236)\n",
    "\n",
    "def preprocess_observation(obs):\n",
    "    img = obs[34:194:2, ::2].reshape(-1,3)\n",
    "    tmp = np.full(shape=(80*80),fill_value=0.0,dtype=np.float32)\n",
    "    for i, c in enumerate(img):\n",
    "        c = tuple(c)\n",
    "        if c in {green_paddle_color, red_paddle_color,ball_color}:\n",
    "            tmp[i] = 1.0\n",
    "        else:\n",
    "            tmp[i] = 0.0\n",
    "    return tmp.reshape(80, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "for _ in range(25):\n",
    "    obs, _,_, _ = env.step(0)\n",
    "\n",
    "plt.figure(figsize=(11,7))\n",
    "plt.subplot(121)\n",
    "plt.title('Original observation (160 x 210 RGB)')\n",
    "plt.imshow(obs)\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.title('Preprocessed observation (80x 80 grayscale)')\n",
    "plt.imshow(preprocess_observation(obs), interpolation='nearest',cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_observations(preprocess_observations,dim_factor=0.75):\n",
    "    dimmed = [obs * (dim_factor ** idx)\n",
    "              for idx, obs in enumerate(reversed(preprocess_observations))]\n",
    "    return np.max(np.array(dimmed), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_observations_per_state = 3\n",
    "\n",
    "obs = env.reset()\n",
    "for _ in range(20):\n",
    "    obs, _, _, _ = env.step(0)\n",
    "\n",
    "preprocess_observations = []\n",
    "for _ in range(n_observations_per_state):\n",
    "    obs, _, _, _ = env.step(2)\n",
    "    preprocess_observations.append(preprocess_observation(obs))\n",
    "\n",
    "img = combine_observations(preprocess_observations)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.title('Combined observations as a single state')\n",
    "plt.imshow(img, interpolation='nearest',cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0701 06:36:03.550806  9840 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now we are going to build the DQN. \n",
    "Like the DQN for Pac-Man, \n",
    "this model will train 3 convolutional layers,\n",
    "then a hidden fully connected layer,\n",
    "then finally a fully connected layer with 6 neurons, \n",
    "one representing each possible output\n",
    "\"\"\"\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "input_width = 80\n",
    "input_height = 80\n",
    "input_channels = 1\n",
    "\n",
    "conv_n_maps = [32, 64, 64]\n",
    "conv_kernel_sizes = [9, 5, 3]\n",
    "conv_kernel_strides = [4, 2, 1]\n",
    "conv_paddings = ['VALID'] *3\n",
    "conv_activation = [tf.nn.relu] * 3\n",
    "\n",
    "n_hidden_in = 5 * 5 * 64\n",
    "n_hidden = 512\n",
    "hidden_activation = tf.nn.relu\n",
    "n_outputs = env.action_space.n\n",
    "\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This model will use two DQNs,\n",
    "an online DQN and a target DQN. \n",
    "The online DQN learns new parameters at each training step.\n",
    "The target DQN is used to compute the target Q-Values \n",
    "for the online DQN's loss function during training. \n",
    "The online DQN's parameters are copied to the target\n",
    "DQN at regular intervals.\n",
    "\"\"\"\n",
    "\n",
    "def q_network(X_state, name):\n",
    "    prev_layer = X_state\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        for n_maps, kernel_size, strides, padding, activation in zip(\n",
    "                conv_n_maps, conv_kernel_sizes, conv_kernel_strides, conv_paddings,\n",
    "                conv_activation):\n",
    "            prev_layer = tf.layers.conv2d(prev_layer,filters=n_maps,\n",
    "                                          kernel_size=kernel_size,\n",
    "                                          strides=strides,padding=padding,\n",
    "                                          kernel_initializer=he_init,activation=activation)\n",
    "        flattened = tf.reshape(prev_layer, [-1, n_hidden_in])\n",
    "        hidden = tf.layers.dense(flattened, n_hidden,\n",
    "                                 activation=hidden_activation,\n",
    "                                 kernel_initializer=he_init)\n",
    "        outputs = tf.layers.dense(hidden, n_outputs, kernel_initializer=he_init)\n",
    "    trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                         scope=scope.name)\n",
    "    trainable_vars_by_name = {var.name[len(scope.name):]:var for var in trainable_vars}\n",
    "    return outputs, trainable_vars_by_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0701 06:36:05.777945  9840 deprecation.py:323] From <ipython-input-16-a3fbd879d20f>:20: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "W0701 06:36:05.778944  9840 deprecation.py:323] From C:\\installs\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\layers\\convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W0701 06:36:05.829783  9840 deprecation.py:323] From <ipython-input-16-a3fbd879d20f>:24: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n"
     ]
    }
   ],
   "source": [
    "# starting DQN definition\n",
    "\n",
    "X_state = tf.placeholder(tf.float32, shape=(None, input_height, input_width, input_channels))\n",
    "online_q_values, online_vars = q_network(X_state, 'q_networks/online')\n",
    "target_q_values, target_vars = q_network(X_state, 'q_networks/target')\n",
    "copy_ops = [var.assign(online_vars[name]) for name,var in target_vars.items()]\n",
    "copy_online_to_target = tf.group(*copy_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining traning objective\n",
    "\n",
    "learning_rate = 1e-3\n",
    "momentum = 0.95\n",
    "\n",
    "with tf.variable_scope('training') as scope:\n",
    "    X_action = tf.placeholder(tf.int32, shape=(None,))\n",
    "    y = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "    Q_target = tf.reduce_sum(online_q_values * tf.one_hot(X_action, n_outputs),\n",
    "                             axis=1, keepdims=True)\n",
    "    error = tf.abs(y- Q_target)\n",
    "    loss = tf.reduce_mean(tf.square(error))\n",
    "    \n",
    "    global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=True)\n",
    "    \n",
    "    training_op = optimizer.minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This model will sample past experiences from a _Replay Memory_, this will hopefully help the model learn what higher level patterns to pay attention to to find the right action. It also reduces the chance that the model's behavior gets too correlated to it's most recent experiences.\n",
    "\n",
    "The replay memory will store its data in the kernel's memory.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, maxlen):\n",
    "        self.maxlen = maxlen\n",
    "        self.buf = np.empty(shape=maxlen, dtype=np.object)\n",
    "        self.index = 0\n",
    "        self.length  = 0\n",
    "    \n",
    "    def append(self, data):\n",
    "        self.buf[self.index] = data\n",
    "        self.index += 1\n",
    "        self.index %= self.maxlen\n",
    "        self.length = min(self.length + 1, self.maxlen)\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return self.buf[np.random.randint(self.length, size=batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_size = 200000\n",
    "replay_memory = ReplayMemory(replay_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_memories(batch_size):\n",
    "    cols = [[], [], [], []]\n",
    "    for memory in replay_memory.sample(batch_size):\n",
    "        for col, value in zip(cols, memory):\n",
    "            col.append(value)\n",
    "    cols = [np.array(col) for col in cols]\n",
    "    return cols[0], cols[1], cols[2].reshape(-1,1), cols[3], cols[4].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now let's define the model's policy during training. \n",
    "Just like in MsPacMan.ipynb, we will use an 𝜀-greedy policy.\n",
    "\"\"\"\n",
    "\n",
    "eps_min = 0.1\n",
    "eps_max = 1.0\n",
    "eps_decay_steps = 6000000\n",
    "\n",
    "def epsilon_greedy(q_values, step):\n",
    "    epsilon = min(eps_min,\n",
    "                  eps_max- ((eps_max - eps_min) * (step/eps_decay_steps)))\n",
    "    if np.random.random() < epsilon:\n",
    "        return np.random.randint(n_outputs)\n",
    "    return np.argmax(q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now we will train the model to play some Pong.\n",
    "The model will input an action once every 3 frames.\n",
    "The preprocessing functions defined above will use the 3 frames \n",
    "to compute the state the model will use to \n",
    "\"\"\"\n",
    "\n",
    "n_steps = 10000000\n",
    "training_start = 100000\n",
    "training_interval = 4\n",
    "save_steps = 1000\n",
    "copy_steps = 10000\n",
    "dsicount_rate =0.95\n",
    "skip_start = 20\n",
    "batch_size =50\n",
    "iteration = 0\n",
    "done = True\n",
    "# to reset the environment at the start\n",
    "\n",
    "loss_val = np.infty\n",
    "game_length = 0\n",
    "total_max_q = 0.0\n",
    "mean_max_q = 0.0\n",
    "\n",
    "checkpoint_path = \"./pong_dqn.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function to get the environment state for the model\n",
    "\n",
    "def perform_action(action):\n",
    "    preprocess_observations = []\n",
    "    total_reward = 0.0\n",
    "    for i in range(3):\n",
    "        obs, reward,done,info = env.step(action)\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            for _ in range(i,3):\n",
    "                preprocess_observations.append(preprocess_observation(obs))\n",
    "            break\n",
    "        else:\n",
    "            preprocess_observations.append(preprocess_observation(obs))\n",
    "    return combine_observations(preprocess_observations).reshape(80, 80,1), total_reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100000\tTrainind step 0/10000000 (0.0) %\tLoss   inf \tMean Max-Q 0.114701 "
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-f9a87881518f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;31m# sample memories from replay memeory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mX_state_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_action_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_next_state_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontinues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_memories\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         next_q_values = target_q_values.eval(\n\u001b[0;32m     51\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX_state\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX_next_state_val\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-bff0ade6a6cc>\u001b[0m in \u001b[0;36msample_memories\u001b[1;34m(batch_size)\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "# main training loop \n",
    "with tf.Session() as sess:\n",
    "    if os.path.isfile(checkpoint_path + '.index'):\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        init.run()\n",
    "        copy_online_to_target.run()\n",
    "    while True:\n",
    "        step = global_step.eval()\n",
    "        if step >= n_steps:\n",
    "            break\n",
    "        iteration +=1 \n",
    "        print(\"\\rIteration {}\\tTrainind step {}/{} ({:.1f}) %\\tLoss {:5f} \\tMean Max-Q {:5f} \".format(\n",
    "            iteration, step, n_steps, 100 * step / n_steps, loss_val, mean_max_q),\n",
    "                 end='')\n",
    "        if done:\n",
    "            obs = env.reset()\n",
    "            for _ in range(skip_start):\n",
    "                obs, reward, done, info = env.step(0)\n",
    "            state, reward, done = perform_action(0)\n",
    "            \n",
    "        \n",
    "        # Evaluate the next action of the agent\n",
    "        q_values = online_q_values.eval(feed_dict={X_state:[state]})\n",
    "        action = epsilon_greedy(q_values, step)\n",
    "        \n",
    "        # online dqn plays the game\n",
    "        next_state, reward, done = perform_action(action)\n",
    "        \n",
    "        # save the result in ReplayMemory\n",
    "        replay_memory.append((state,action,reward,next_state, 1.0 -done))\n",
    "        state = next_state\n",
    "        \n",
    "        # compute statistics which help us monitor how training is going\n",
    "        total_max_q += q_values.max()\n",
    "        game_length += 1\n",
    "        if done :\n",
    "            mean_max_q = total_max_q / game_length\n",
    "            total_max_q = 0.0\n",
    "            game_length = 0\n",
    "        \n",
    "        # only train after the warmup rounds and only everyfew rounds\n",
    "        if iteration < training_start or iteration % training_interval != 0:\n",
    "            continue\n",
    "        \n",
    "        # sample memories from replay memeory\n",
    "        X_state_val, X_action_val, rewards,X_next_state_val, continues = sample_memories(batch_size)\n",
    "        next_q_values = target_q_values.eval(\n",
    "            feed_dict={X_state:X_next_state_val}\n",
    "        )\n",
    "        max_next_q_values = np.max(next_q_values,axis=1, keepdims=True)\n",
    "        y_val = rewards + continues * discount_rate * max_next_q_values\n",
    "        \n",
    "        # train the online DQN\n",
    "        _, loss_val = sesss.run([training_op, loss], feed_dict={\n",
    "            X_state: X_state_val,\n",
    "            X_action: X_action_val,\n",
    "            y: y_val\n",
    "        })\n",
    "        \n",
    "        # copy the online DQN to the taret DQN\n",
    "        if step % copy_steps == 0:\n",
    "            copy_online_to_target.run()\n",
    "        \n",
    "        # regularly save the model\n",
    "        if step and step % save_steps == 0:\n",
    "            saver.save(sess,checkpoint_psth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_observations = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,checkpoint_path)\n",
    "    \n",
    "    def dqn_policy(obs, i):\n",
    "        if len(preprocess_observations) < 3:\n",
    "            preprocess_observations.append(preprocess_observation(obs))\n",
    "            if len(preprocess_observations) == 3:\n",
    "                state = combine_observations(preprocess_observations)\n",
    "                q_values = online_q_values.eval(\n",
    "                    feed_dict = {X_state: [state.reshape(80,80,1)]}\n",
    "                )\n",
    "                dqn_policy.cur_action = np.argmax(q_values)\n",
    "            return dqn_policy.cur_action\n",
    "        preprocess_observations[i%3] = preprocess_observation(obs)\n",
    "        if i %3 == 2:\n",
    "            state = combine_observations(preprocess_observations)\n",
    "            q_values = online_q_values.eval(\n",
    "                feed_dict={X_state: [state.reshape(80,80,1)]}\n",
    "            )\n",
    "            dqn_policy.cur_action = np.argmax(q_values)\n",
    "        return dqn_policy.cur_action\n",
    "    dqn_policy.cur_action = 0\n",
    "    \n",
    "\n",
    "    frames = run_episode(dqn_policy, n_max_steps=10000)\n",
    "\n",
    "plot_animation(frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
