{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic RNN\n",
    "import tensorflow as tf\n",
    "\n",
    "n_inputs =3\n",
    "n_neurons = 5\n",
    "\n",
    "X0 =  tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "Wx = tf.Variable(tf.random_normal(shape=[n_inputs, n_neurons], dtype=tf.float32))\n",
    "Wy = tf.Variable(tf.random_normal(shape=[n_neurons, n_neurons], dtype=tf.float32))\n",
    "b = tf.Variable(tf.zeros([1, n_neurons], dtype=tf.float32))\n",
    "\n",
    "Y0 = tf.tanh(tf.matmul(X0, Wx) +b)\n",
    "Y1 = tf.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) + b)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X0_batch = np.array([[0,1,2], [3,4,5], [6,7,8], [9,0,1]])\n",
    "X1_batch = np.array([[9,8,7],[0,0,0],[6,5,4],[3,2,1]])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0:X0_batch, X1:X1_batch})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.736362    0.56424904 -0.9928428   0.99697137  0.9957681 ]\n",
      " [ 0.9999985   0.98514026 -1.          1.          1.        ]\n",
      " [ 1.          0.9995978  -1.          1.          1.        ]\n",
      " [ 0.99999887  0.9990503  -0.99999994  0.99999994  0.99580586]]\n"
     ]
    }
   ],
   "source": [
    "print(Y0_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.9999874  -1.          1.          1.        ]\n",
      " [ 0.69753206  0.6118082  -0.90616906  0.9795825  -0.8114883 ]\n",
      " [ 1.          0.9986853  -1.          1.          1.        ]\n",
      " [ 0.9999879   0.9524181  -0.99999994  0.99996644  0.9973081 ]]\n"
     ]
    }
   ],
   "source": [
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BasicRNNCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# static unrolling through time\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "# we create input palceholders\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "#  we create BasicRNNCell which you can think of as a factory that creates copies of the cell to build the unrolled RNN\n",
    "\n",
    "output_seqs,states = tf.contrib.rnn.static_rnn(\n",
    "                     basic_cell, [X0, X1], dtype=tf.float32)\n",
    "# we call static rnn which calls the BasicRNNCell creating two copies of cell\n",
    "\n",
    "\n",
    "Y0, Y1 = output_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnn/basic_rnn_cell/Tanh:0\", shape=(?, 5), dtype=float32)\n",
      "Tensor(\"rnn/basic_rnn_cell/Tanh_1:0\", shape=(?, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# if there wer 50 time steps, it wouldnot be ery convenient to have ot \n",
    "# define 50 input placeholders and 50 output tensors\n",
    "\n",
    "print(Y0)\n",
    "print(Y1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the packing sequences\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0:X0_batch, X1:X1_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.6220045 ,  0.3434742 ,  0.5967921 ,  0.5467581 , -0.11334981],\n",
       "       [-0.8740386 ,  0.9972768 ,  0.987609  ,  0.9661833 , -0.81035984],\n",
       "       [-0.96196574,  0.9999924 ,  0.9996922 ,  0.99798304, -0.972817  ],\n",
       "       [-0.27229077,  0.9997892 ,  0.99158883,  0.99976593, -0.99935156]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y0_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.62965757,  0.99999994,  0.9999669 ,  0.9991317 , -0.9964192 ],\n",
       "       [ 0.6258266 ,  0.7319028 ,  0.891579  , -0.2367793 , -0.00984494],\n",
       "       [ 0.22992855,  0.99999607,  0.9997939 ,  0.9622914 , -0.95374256],\n",
       "       [ 0.55169165,  0.9969307 ,  0.97981477,  0.08551132, -0.7642403 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow_graph_in_jupyter import show_graph\n",
    "\n",
    "# show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packing Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following cide builds the same RNN again but thistime it takes asingle input \n",
    "# placeholder of hsape [None, n_steps, n_inputs ] where the first  fimensions is the mini batch size\\\n",
    "# Then it extract thelist of input sequences for each time step\n",
    "# X_seqs is a Python list of n_steps tensors of shape [None,n_inputs]\n",
    "# where once again the first dimension is the mini batch size\n",
    "# To do this, we first swap using transpose function so that the time steps are now the first dimension \n",
    "# then we use the unstack function. The next twolines are the sam\n",
    "# finally we merge the the output tensors into a single tensor using stack() function\n",
    "# and we sqap the first two fimension to get a final outputs tensor\n",
    "# of shape [None, n_steps, n_neurons]\n",
    "\n",
    "n_steps =2\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps,n_inputs])\n",
    "X_seqs = tf.unstack(tf.transpose(X,perm=[1,0,2]))\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell, X_seqs, dtype=tf.float32)\n",
    "outputs = tf.transpose(tf.stack(output_seqs), perm=[1,0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.80800104 -0.25818652  0.88132834  0.79292494 -0.08273872]\n",
      "  [-0.5822327  -0.9999026   0.999995   -0.657447   -0.96924794]]\n",
      "\n",
      " [[ 0.8161503  -0.9309901   0.99883807  0.84217244 -0.7897056 ]\n",
      "  [ 0.5496408  -0.85100687  0.21461645 -0.20366207  0.8525351 ]]\n",
      "\n",
      " [[ 0.82398736 -0.9956768   0.9999893   0.88048846 -0.9679276 ]\n",
      "  [-0.33215857 -0.999035    0.9979041  -0.7774459  -0.4956271 ]]\n",
      "\n",
      " [[-0.9999593  -0.999779    0.14563009 -0.9997508  -0.93437034]\n",
      "  [-0.87933636 -0.6990654  -0.65328014 -0.6297835  -0.6142405 ]]]\n"
     ]
    }
   ],
   "source": [
    "X_batch= np.array([\n",
    "    [[0,1,2], [9,8,7]],\n",
    "    [[3,4,5], [0,0,0]],\n",
    "    [[6,7,8], [6,5,4]],\n",
    "    [[9,0,1], [3,2,1]]\n",
    "])\n",
    "g = tf.Graph()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X:X_batch})\n",
    "\n",
    "# this stillgets one graph containing unit cell per time step\n",
    "# If there were 50 time steps the graph would look pretty ugly\n",
    "print(outputs_val)\n",
    "\n",
    "# with large graph we will also get out of memory errors so that it can\n",
    "# use them to compute gradients during the reverse pass\n",
    "# thats why we using dynamic rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5822327  -0.9999026   0.999995   -0.657447   -0.96924794]\n",
      " [ 0.5496408  -0.85100687  0.21461645 -0.20366207  0.8525351 ]\n",
      " [-0.33215857 -0.999035    0.9979041  -0.7774459  -0.4956271 ]\n",
      " [-0.87933636 -0.6990654  -0.65328014 -0.6297835  -0.6142405 ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.transpose(outputs_val, axes=[1,0,2])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0616 10:20:31.411031 12108 deprecation.py:323] From <ipython-input-2-6755c56d7f85>:10: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0616 10:20:31.414023 12108 deprecation.py:323] From <ipython-input-2-6755c56d7f85>:11: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "W0616 10:20:31.476860 12108 deprecation.py:323] From C:\\installs\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:456: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "W0616 10:20:31.487831 12108 deprecation.py:506] From C:\\installs\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "n_steps =2\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_batch =  np.array([\n",
    "    [[0,1,2], [9,8,7]],\n",
    "    [[3,4,5], [0,0,0]],\n",
    "    [[6,7,8], [6,5,4]],\n",
    "    [[9,0,1], [3,2,1]]\n",
    "])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X:X_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.3075267   0.5299915   0.16965647  0.87184805  0.58252114]\n",
      "  [-0.9981262   0.9964085  -0.09262892 -0.39578518  0.97315013]]\n",
      "\n",
      " [[-0.9239652   0.97164756  0.09598505  0.93754584  0.9429492 ]\n",
      "  [ 0.47932312 -0.8938842   0.2604586  -0.45113435 -0.44469807]]\n",
      "\n",
      " [[-0.9941193   0.9986546   0.02124681  0.97010124  0.9934848 ]\n",
      "  [-0.93894494  0.74343777 -0.0715929  -0.8035607   0.7878499 ]]\n",
      "\n",
      " [[-0.99964064  0.9620414  -0.99611646 -0.9999498  -0.9915379 ]\n",
      "  [-0.41506955  0.73790824 -0.7738236  -0.97888213  0.9177495 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val)\n",
    "\n",
    "# show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the sequence lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0616 10:26:55.937911 12108 deprecation.py:323] From C:\\installs\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "seq_length = tf.placeholder(tf.int32, [None])\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32,\n",
    "                                    sequence_length=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = np.array([\n",
    "    #step 0   step 1\n",
    "    [[0,1,2], [9,8,7]], # instance 1\n",
    "    [[3,4,5], [0,0,0]], # Padded Instance 2\n",
    "    [[6,7,8], [6,5,4]], # instance 3\n",
    "    [[9,0,1], [3,2,1]],  # instance 4\n",
    "])\n",
    "\n",
    "seq_length_batch = np.array([2,1,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val, states_val = sess.run(\n",
    "        [outputs, states],feed_dict={X:X_batch, seq_length: seq_length_batch })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.11812522 -0.20228527  0.11452613  0.11399005  0.3338867 ]\n",
      "  [-0.99728656 -0.9996351   0.75922894 -0.99910766  0.24618293]]\n",
      "\n",
      " [[-0.87457997 -0.94072527  0.44783533 -0.8127231   0.474531  ]\n",
      "  [ 0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-0.9887129  -0.997192    0.69051933 -0.98316467  0.5945068 ]\n",
      "  [-0.96373564 -0.9832916   0.7888061  -0.96899116 -0.5954966 ]]\n",
      "\n",
      " [[-0.9998727  -0.9999861  -0.9860169  -0.9999886  -0.65876055]\n",
      "  [-0.8518146  -0.9395353   0.88231933 -0.6496556  -0.8854977 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.99728656 -0.9996351   0.75922894 -0.99910766  0.24618293]\n",
      " [-0.87457997 -0.94072527  0.44783533 -0.8127231   0.474531  ]\n",
      " [-0.96373564 -0.9832916   0.7888061  -0.96899116 -0.5954966 ]\n",
      " [-0.8518146  -0.9395353   0.88231933 -0.6496556  -0.8854977 ]]\n"
     ]
    }
   ],
   "source": [
    "print(states_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a sequence classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_steps =28\n",
    "n_inputs = 28\n",
    "n_neurons = 150\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "# these are the two lines that are defining a RNN\n",
    "basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X # from feed_dict\n",
    "                                    ,dtype=tf.float32)\n",
    "\n",
    "# dynamic and static rnn bothe functions calls the BasicRNNCell call function per input\n",
    "# createing two copise with n_neurons no. of connection between the layers\n",
    "# it returns twoobjects  python list containing the output tensors foreach step and final states of the network\n",
    "#in basic cell the final state is equal to the last output\n",
    "\n",
    "logits = tf.layers.dense(states, n_outputs)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y  # from feed_dict\n",
    "                                                          , logits=logits)\n",
    "\n",
    "loss= tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "training_op = optimizer.minimize(loss)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train), (X_test,y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28 * 28)/ 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28 * 28)/255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch\n",
    "        # this is a generator\n",
    "        # multiple returns to single call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape((-1, n_steps,n_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Last batch accuracy:  0.9266667 Test accuracy: 0.9357\n",
      "1 Last batch accuracy:  0.98 Test accuracy: 0.9441\n",
      "2 Last batch accuracy:  0.97333336 Test accuracy: 0.9637\n",
      "3 Last batch accuracy:  0.9533333 Test accuracy: 0.9549\n",
      "4 Last batch accuracy:  0.97333336 Test accuracy: 0.9657\n",
      "5 Last batch accuracy:  0.98 Test accuracy: 0.9636\n",
      "6 Last batch accuracy:  0.94666666 Test accuracy: 0.9664\n",
      "7 Last batch accuracy:  0.98 Test accuracy: 0.9691\n",
      "8 Last batch accuracy:  0.97333336 Test accuracy: 0.9743\n",
      "9 Last batch accuracy:  0.98 Test accuracy: 0.9733\n",
      "10 Last batch accuracy:  0.96666664 Test accuracy: 0.965\n",
      "11 Last batch accuracy:  0.97333336 Test accuracy: 0.9682\n",
      "12 Last batch accuracy:  0.96666664 Test accuracy: 0.9716\n",
      "13 Last batch accuracy:  0.98 Test accuracy: 0.9656\n",
      "14 Last batch accuracy:  0.9866667 Test accuracy: 0.9715\n",
      "15 Last batch accuracy:  0.9866667 Test accuracy: 0.9696\n",
      "16 Last batch accuracy:  0.9866667 Test accuracy: 0.9743\n",
      "17 Last batch accuracy:  0.98 Test accuracy: 0.9742\n",
      "18 Last batch accuracy:  0.99333334 Test accuracy: 0.9749\n",
      "19 Last batch accuracy:  0.99333334 Test accuracy: 0.974\n",
      "20 Last batch accuracy:  0.99333334 Test accuracy: 0.9785\n",
      "21 Last batch accuracy:  0.97333336 Test accuracy: 0.9683\n",
      "22 Last batch accuracy:  0.98 Test accuracy: 0.975\n",
      "23 Last batch accuracy:  1.0 Test accuracy: 0.9711\n",
      "24 Last batch accuracy:  1.0 Test accuracy: 0.9748\n",
      "25 Last batch accuracy:  0.97333336 Test accuracy: 0.9775\n",
      "26 Last batch accuracy:  0.97333336 Test accuracy: 0.9767\n",
      "27 Last batch accuracy:  1.0 Test accuracy: 0.9794\n",
      "28 Last batch accuracy:  1.0 Test accuracy: 0.9777\n",
      "29 Last batch accuracy:  1.0 Test accuracy: 0.974\n",
      "30 Last batch accuracy:  0.99333334 Test accuracy: 0.9732\n",
      "31 Last batch accuracy:  0.9866667 Test accuracy: 0.9769\n",
      "32 Last batch accuracy:  0.99333334 Test accuracy: 0.9786\n",
      "33 Last batch accuracy:  1.0 Test accuracy: 0.9765\n",
      "34 Last batch accuracy:  0.99333334 Test accuracy: 0.976\n",
      "35 Last batch accuracy:  0.98 Test accuracy: 0.978\n",
      "36 Last batch accuracy:  1.0 Test accuracy: 0.9775\n",
      "37 Last batch accuracy:  0.9866667 Test accuracy: 0.9761\n",
      "38 Last batch accuracy:  0.9866667 Test accuracy: 0.9745\n",
      "39 Last batch accuracy:  0.9866667 Test accuracy: 0.9808\n",
      "40 Last batch accuracy:  1.0 Test accuracy: 0.9792\n",
      "41 Last batch accuracy:  0.9866667 Test accuracy: 0.9777\n",
      "42 Last batch accuracy:  0.99333334 Test accuracy: 0.9755\n",
      "43 Last batch accuracy:  0.99333334 Test accuracy: 0.9713\n",
      "44 Last batch accuracy:  0.9866667 Test accuracy: 0.9762\n",
      "45 Last batch accuracy:  0.9866667 Test accuracy: 0.9786\n",
      "46 Last batch accuracy:  0.99333334 Test accuracy: 0.9783\n",
      "47 Last batch accuracy:  0.99333334 Test accuracy: 0.9785\n",
      "48 Last batch accuracy:  0.99333334 Test accuracy: 0.9785\n",
      "49 Last batch accuracy:  0.99333334 Test accuracy: 0.9794\n",
      "50 Last batch accuracy:  1.0 Test accuracy: 0.9781\n",
      "51 Last batch accuracy:  1.0 Test accuracy: 0.9781\n",
      "52 Last batch accuracy:  0.98 Test accuracy: 0.9739\n",
      "53 Last batch accuracy:  1.0 Test accuracy: 0.9732\n",
      "54 Last batch accuracy:  0.99333334 Test accuracy: 0.9757\n",
      "55 Last batch accuracy:  0.9866667 Test accuracy: 0.9774\n",
      "56 Last batch accuracy:  0.99333334 Test accuracy: 0.9793\n",
      "57 Last batch accuracy:  0.99333334 Test accuracy: 0.9794\n",
      "58 Last batch accuracy:  1.0 Test accuracy: 0.9769\n",
      "59 Last batch accuracy:  1.0 Test accuracy: 0.9754\n",
      "60 Last batch accuracy:  0.99333334 Test accuracy: 0.9804\n",
      "61 Last batch accuracy:  0.99333334 Test accuracy: 0.978\n",
      "62 Last batch accuracy:  1.0 Test accuracy: 0.9791\n",
      "63 Last batch accuracy:  1.0 Test accuracy: 0.9747\n",
      "64 Last batch accuracy:  0.96666664 Test accuracy: 0.9677\n",
      "65 Last batch accuracy:  0.99333334 Test accuracy: 0.9787\n",
      "66 Last batch accuracy:  1.0 Test accuracy: 0.9768\n",
      "67 Last batch accuracy:  1.0 Test accuracy: 0.9804\n",
      "68 Last batch accuracy:  0.9866667 Test accuracy: 0.9749\n",
      "69 Last batch accuracy:  0.99333334 Test accuracy: 0.9809\n",
      "70 Last batch accuracy:  1.0 Test accuracy: 0.9755\n",
      "71 Last batch accuracy:  1.0 Test accuracy: 0.9742\n",
      "72 Last batch accuracy:  0.99333334 Test accuracy: 0.9762\n",
      "73 Last batch accuracy:  1.0 Test accuracy: 0.9799\n",
      "74 Last batch accuracy:  1.0 Test accuracy: 0.9794\n",
      "75 Last batch accuracy:  1.0 Test accuracy: 0.9777\n",
      "76 Last batch accuracy:  1.0 Test accuracy: 0.9774\n",
      "77 Last batch accuracy:  0.98 Test accuracy: 0.9768\n",
      "78 Last batch accuracy:  0.9866667 Test accuracy: 0.9781\n",
      "79 Last batch accuracy:  1.0 Test accuracy: 0.9789\n",
      "80 Last batch accuracy:  1.0 Test accuracy: 0.9774\n",
      "81 Last batch accuracy:  0.98 Test accuracy: 0.9763\n",
      "82 Last batch accuracy:  0.9866667 Test accuracy: 0.9804\n",
      "83 Last batch accuracy:  1.0 Test accuracy: 0.9788\n",
      "84 Last batch accuracy:  1.0 Test accuracy: 0.9779\n",
      "85 Last batch accuracy:  0.99333334 Test accuracy: 0.9741\n",
      "86 Last batch accuracy:  1.0 Test accuracy: 0.9787\n",
      "87 Last batch accuracy:  0.98 Test accuracy: 0.9809\n",
      "88 Last batch accuracy:  1.0 Test accuracy: 0.9795\n",
      "89 Last batch accuracy:  1.0 Test accuracy: 0.9791\n",
      "90 Last batch accuracy:  0.9866667 Test accuracy: 0.9772\n",
      "91 Last batch accuracy:  0.99333334 Test accuracy: 0.9778\n",
      "92 Last batch accuracy:  1.0 Test accuracy: 0.9754\n",
      "93 Last batch accuracy:  0.9866667 Test accuracy: 0.9757\n",
      "94 Last batch accuracy:  1.0 Test accuracy: 0.9792\n",
      "95 Last batch accuracy:  0.99333334 Test accuracy: 0.9788\n",
      "96 Last batch accuracy:  0.98 Test accuracy: 0.968\n",
      "97 Last batch accuracy:  1.0 Test accuracy: 0.9772\n",
      "98 Last batch accuracy:  1.0 Test accuracy: 0.9778\n",
      "99 Last batch accuracy:  0.99333334 Test accuracy: 0.9727\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            X_batch = X_batch.reshape((-1, n_steps,n_inputs ))\n",
    "            sess.run(training_op,feed_dict={X:X_batch,y: y_batch})\n",
    "        acc_batch = accuracy.eval(feed_dict={X:X_batch, y:y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X:X_test, y:y_test})\n",
    "        print(epoch,\"Last batch accuracy: \", acc_batch, \"Test accuracy:\", acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layer RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi layer RNN\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "n_steps = 28\n",
    "n_inputs = 28\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None,n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0616 11:33:53.245198 12108 deprecation.py:323] From <ipython-input-31-766197b0afd1>:7: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "n_neurons = 100\n",
    "n_layers = 2\n",
    "\n",
    "layers = [tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu)for layer in range(n_layers)]\n",
    "# layers is not required here\n",
    "\n",
    "multi_layer_cell = tf.nn.rnn_cell.MultiRNNCell(layers)\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_concat = tf.concat(axis=1, values=states)\n",
    "\n",
    "logits = tf.layers.dense(states_concat,n_outputs)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 last batch accuracy:  0.93333334 test_accuracy:  0.9233\n",
      "1 last batch accuracy:  0.97333336 test_accuracy:  0.9529\n",
      "2 last batch accuracy:  0.94 test_accuracy:  0.9631\n",
      "3 last batch accuracy:  0.98 test_accuracy:  0.9662\n",
      "4 last batch accuracy:  0.97333336 test_accuracy:  0.9651\n",
      "5 last batch accuracy:  0.9866667 test_accuracy:  0.9756\n",
      "6 last batch accuracy:  0.96666664 test_accuracy:  0.9717\n",
      "7 last batch accuracy:  0.97333336 test_accuracy:  0.9719\n",
      "8 last batch accuracy:  0.9866667 test_accuracy:  0.9744\n",
      "9 last batch accuracy:  0.98 test_accuracy:  0.9779\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            X_batch = X_batch.reshape((-1,n_steps,n_inputs ))\n",
    "            sess.run(training_op, feed_dict={X:X_batch, y:y_batch})\n",
    "        acc_batch = accuracy.eval(feed_dict={X:X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X:X_test, y: y_test})\n",
    "        print(epoch, \"last batch accuracy: \", acc_batch, \"test_accuracy: \", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
