{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic RNN\n",
    "import tensorflow as tf\n",
    "\n",
    "n_inputs =3\n",
    "n_neurons = 5\n",
    "\n",
    "X0 =  tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "Wx = tf.Variable(tf.random_normal(shape=[n_inputs, n_neurons], dtype=tf.float32))\n",
    "Wy = tf.Variable(tf.random_normal(shape=[n_neurons, n_neurons], dtype=tf.float32))\n",
    "b = tf.Variable(tf.zeros([1, n_neurons], dtype=tf.float32))\n",
    "\n",
    "Y0 = tf.tanh(tf.matmul(X0, Wx) +b)\n",
    "Y1 = tf.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) + b)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X0_batch = np.array([[0,1,2], [3,4,5], [6,7,8], [9,0,1]])\n",
    "X1_batch = np.array([[9,8,7],[0,0,0],[6,5,4],[3,2,1]])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0:X0_batch, X1:X1_batch})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.736362    0.56424904 -0.9928428   0.99697137  0.9957681 ]\n",
      " [ 0.9999985   0.98514026 -1.          1.          1.        ]\n",
      " [ 1.          0.9995978  -1.          1.          1.        ]\n",
      " [ 0.99999887  0.9990503  -0.99999994  0.99999994  0.99580586]]\n"
     ]
    }
   ],
   "source": [
    "print(Y0_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.9999874  -1.          1.          1.        ]\n",
      " [ 0.69753206  0.6118082  -0.90616906  0.9795825  -0.8114883 ]\n",
      " [ 1.          0.9986853  -1.          1.          1.        ]\n",
      " [ 0.9999879   0.9524181  -0.99999994  0.99996644  0.9973081 ]]\n"
     ]
    }
   ],
   "source": [
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BasicRNNCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# static unrolling through time\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "# we create input palceholders\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "#  we create BasicRNNCell which you can think of as a factory that creates copies of the cell to build the unrolled RNN\n",
    "\n",
    "output_seqs,states = tf.contrib.rnn.static_rnn(\n",
    "                     basic_cell, [X0, X1], dtype=tf.float32)\n",
    "# we call static rnn which calls the BasicRNNCell creating two copies of cell\n",
    "\n",
    "\n",
    "Y0, Y1 = output_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnn/basic_rnn_cell/Tanh:0\", shape=(?, 5), dtype=float32)\n",
      "Tensor(\"rnn/basic_rnn_cell/Tanh_1:0\", shape=(?, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# if there wer 50 time steps, it wouldnot be ery convenient to have ot \n",
    "# define 50 input placeholders and 50 output tensors\n",
    "\n",
    "print(Y0)\n",
    "print(Y1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the packing sequences\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0:X0_batch, X1:X1_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.6220045 ,  0.3434742 ,  0.5967921 ,  0.5467581 , -0.11334981],\n",
       "       [-0.8740386 ,  0.9972768 ,  0.987609  ,  0.9661833 , -0.81035984],\n",
       "       [-0.96196574,  0.9999924 ,  0.9996922 ,  0.99798304, -0.972817  ],\n",
       "       [-0.27229077,  0.9997892 ,  0.99158883,  0.99976593, -0.99935156]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y0_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.62965757,  0.99999994,  0.9999669 ,  0.9991317 , -0.9964192 ],\n",
       "       [ 0.6258266 ,  0.7319028 ,  0.891579  , -0.2367793 , -0.00984494],\n",
       "       [ 0.22992855,  0.99999607,  0.9997939 ,  0.9622914 , -0.95374256],\n",
       "       [ 0.55169165,  0.9969307 ,  0.97981477,  0.08551132, -0.7642403 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow_graph_in_jupyter import show_graph\n",
    "\n",
    "# show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packing Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following cide builds the same RNN again but thistime it takes asingle input \n",
    "# placeholder of hsape [None, n_steps, n_inputs ] where the first  fimensions is the mini batch size\\\n",
    "# Then it extract thelist of input sequences for each time step\n",
    "# X_seqs is a Python list of n_steps tensors of shape [None,n_inputs]\n",
    "# where once again the first dimension is the mini batch size\n",
    "# To do this, we first swap using transpose function so that the time steps are now the first dimension \n",
    "# then we use the unstack function. The next twolines are the sam\n",
    "# finally we merge the the output tensors into a single tensor using stack() function\n",
    "# and we sqap the first two fimension to get a final outputs tensor\n",
    "# of shape [None, n_steps, n_neurons]\n",
    "\n",
    "n_steps =2\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps,n_inputs])\n",
    "X_seqs = tf.unstack(tf.transpose(X,perm=[1,0,2]))\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell, X_seqs, dtype=tf.float32)\n",
    "outputs = tf.transpose(tf.stack(output_seqs), perm=[1,0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.80800104 -0.25818652  0.88132834  0.79292494 -0.08273872]\n",
      "  [-0.5822327  -0.9999026   0.999995   -0.657447   -0.96924794]]\n",
      "\n",
      " [[ 0.8161503  -0.9309901   0.99883807  0.84217244 -0.7897056 ]\n",
      "  [ 0.5496408  -0.85100687  0.21461645 -0.20366207  0.8525351 ]]\n",
      "\n",
      " [[ 0.82398736 -0.9956768   0.9999893   0.88048846 -0.9679276 ]\n",
      "  [-0.33215857 -0.999035    0.9979041  -0.7774459  -0.4956271 ]]\n",
      "\n",
      " [[-0.9999593  -0.999779    0.14563009 -0.9997508  -0.93437034]\n",
      "  [-0.87933636 -0.6990654  -0.65328014 -0.6297835  -0.6142405 ]]]\n"
     ]
    }
   ],
   "source": [
    "X_batch= np.array([\n",
    "    [[0,1,2], [9,8,7]],\n",
    "    [[3,4,5], [0,0,0]],\n",
    "    [[6,7,8], [6,5,4]],\n",
    "    [[9,0,1], [3,2,1]]\n",
    "])\n",
    "g = tf.Graph()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X:X_batch})\n",
    "\n",
    "# this stillgets one graph containing unit cell per time step\n",
    "# If there were 50 time steps the graph would look pretty ugly\n",
    "print(outputs_val)\n",
    "\n",
    "# with large graph we will also get out of memory errors so that it can\n",
    "# use them to compute gradients during the reverse pass\n",
    "# thats why we using dynamic rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5822327  -0.9999026   0.999995   -0.657447   -0.96924794]\n",
      " [ 0.5496408  -0.85100687  0.21461645 -0.20366207  0.8525351 ]\n",
      " [-0.33215857 -0.999035    0.9979041  -0.7774459  -0.4956271 ]\n",
      " [-0.87933636 -0.6990654  -0.65328014 -0.6297835  -0.6142405 ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.transpose(outputs_val, axes=[1,0,2])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as ses:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict=)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
